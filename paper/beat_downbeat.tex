% Introduce on beat annotation
\subsection{Beat and Downbeat Tracking Sets}

Over the last 15 years, many annotated datasets for beat and downbeat tracking have appeared in the literature whose primary purpose has been to allow the comparison of newly proposed and existing algorithms. However, the well-known difficulties of sharing the audio component of large annotated datasets has led to a rather ad-hoc usage of different datasets within the literature, and to a lesser extent, the choice of which evaluation metrics are selected to report accuracy. Conversely, the MIREX evaluation campaign provides a more rigid model for evaluation, by withholding access to private test datasets, and instead relying on the submission of the competing algorithms in order to compare them under controlled conditions. To this end, MIREX can be a useful reference point to consider these two music analysis tasks from the perspective of annotated data.  

The MIREX Audio Beat Tracking (ABT) task\footnote{https://www.music-ir.org/mirex/wiki/2006:Audio\_Beat\_Tracking} first appeared in 2006 and ran on a single dataset \cite{moelants04icmpc,mckinney07jnmr} with the performance of the submitted algorithms determined using one evaluation metric, the P-Score. After a brief hiatus, the task reappeared in 2009 with the addition of a dataset of Chopin Mazurkas \cite{sapp07ismir}, and the inclusion of multiple evaluation metrics \cite{davies09techreport}. The task continued to run in this way until the incorporation of the SMC dataset \cite{holzapfel12taslp} in 2012, from which point it has remained constant. In 2014, the Audio Downbeat Estimation (ADE) task\footnote{https://www.music-ir.org/mirex/wiki/2014:Audio\_Downbeat\_Estimation} was launched which comprised six different datasets from diverse geographic and stylistic sources: The Beatles \cite{Mauch2009a}; Hardcore, Jungle, Drum and Bass (HJDB) \cite{hockman12ismir}; Turkish \cite{srinivasamurthy14jnmr}; Ballroom \cite{krebs13ismir}; Carnatic \cite{srinivasamurthy14icassp}; and Cretan \cite{holzapfel14ismir}, with the evaluation conducted using the F-measure. While the datasets contained with these two MIREX tasks are by no means exhaustive, they provide a useful window to explore both how the audio data is chosen and how the annotation is conducted for these MIR tasks. To this end, we provide the following breakdown of different properties including reference to both MIREX and non-MIREX datasets. 

\textbf{Duration}: Unlike the task of structural segmentation, beat and downbeat tracking datasets can be comprised of musical excerpts \cite{hainsworth04jasp,mckinney07jnmr,hockman12ismir, krebs13ismir} rather than full tracks \cite{Goto2002,Mauch2009a,digiorgi2016jaes,eremenko18ismir}. \textbf{Number of annotators}: The initial MIREX beat tracking dataset \cite{mckinney07jnmr} was unique in that it contained the annotations of $40$ different people who tapped the beat to the music excepts. Conversely, other datasets used multiple annotators contributing across the dataset \cite{holzapfel12taslp}, a single annotator for all excerpts \cite{hainsworth04jasp}, or even deriving the annotations in a semi-automatic way from the output of an algorithm \cite{Mauch2009a}. \textbf{Annotation post-processing}: Given some raw tap times or algorithm output, these can either be left unaltered \cite{mckinney07jnmr} or, as is more common, iteratively adjusted until they are considered perceptually accurate by the annotator(s)~\cite{holzapfel12taslp, hainsworth04jasp, hockman12ismir}. \textbf{Style-specificity}: While some datasets are designed to have broad coverage across a range of musical styles \cite{Goto2002,marchand15dafx,hainsworth04jasp}, others target a particular group of styles \cite{hockman12ismir,krebs13ismir}, a single style \cite{eremenko18ismir}, the work of a given artist \cite{Mauch2009a,digiorgi2016jaes} or even multiple versions of the same pieces \cite{sapp07ismir}. \textbf{Western / Non-Western}: Similarly, the make up of the dataset can target underrepresented non-western music \cite{srinivasamurthy14icassp, srinivasamurthy14jnmr,nunes15ismir}. \textbf{Perceived difficulty}: Finally, the choice of musical material can be based upon the perceived difficulty of the musical excerpts, either from the perspective of musical or signal level properties \cite{holzapfel12taslp}. 
